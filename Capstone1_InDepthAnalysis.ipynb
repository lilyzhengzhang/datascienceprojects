{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Reading in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "#display plots inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the raw training datasets: there are four, one with provider information, one with beneficiary data, and two with claim data. \n",
    "fraud_tr = pd.read_csv('/Users/zhengzhang/Downloads/healthcare-provider-fraud-detection-analysis/Train-1542865627584.csv')\n",
    "bene_tr = pd.read_csv('/Users/zhengzhang/Downloads/healthcare-provider-fraud-detection-analysis/Train_Beneficiarydata-1542865627584.csv')\n",
    "inpatient_tr = pd.read_csv('/Users/zhengzhang/Downloads/healthcare-provider-fraud-detection-analysis/Train_Inpatientdata-1542865627584.csv')\n",
    "outpatient_tr = pd.read_csv('/Users/zhengzhang/Downloads/healthcare-provider-fraud-detection-analysis/Train_Outpatientdata-1542865627584.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> In-depth Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use several machine learning algorithm to predict the provider who may be fraudulent. \n",
    "\n",
    "We will investigate the methods for analyzing imbalanced data since <10% of the providers are deemed fraudulent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of inpatient claims each provider submitted and create a panda dataframe with provider ID\n",
    "# and the number of inpatient claims\n",
    "In_Provider=pd.DataFrame([inpatient_tr['Provider'].value_counts().index,inpatient_tr['Provider'].value_counts()]).transpose().rename({0:'Provider',1:'Inpatient_Claim_Number'},axis=1)\n",
    "#In_Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out_Provider=pd.DataFrame([outpatient_tr['Provider'].value_counts().index,outpatient_tr['Provider'].value_counts()]).transpose().rename({0:'Provider',1:'Outpatient_Claim_Number'},axis=1)\n",
    "#Out_Provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the inpatient and outpatient claims per provider dataframes\n",
    "provider_claimnumber=pd.merge(In_Provider,Out_Provider,on='Provider',how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate total amount of inpatient claims each provider submitted and create a panda dataframe with provider ID\n",
    "# and total amount of inpatient claims\n",
    "inreimburse_by_provider=inpatient_tr.groupby('Provider')['InscClaimAmtReimbursed'].sum()\n",
    "inreimburse_temp1=pd.DataFrame([inreimburse_by_provider.index,inreimburse_by_provider])\n",
    "inreimburse_temp2=inreimburse_temp1.transpose()\n",
    "In_Provider_Claim=inreimburse_temp2.rename({0:'Provider',1:'Inpatient_Claim_Amount'},axis=1)\n",
    "#In_Provider_Claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "outreimburse_by_provider=outpatient_tr.groupby('Provider')['InscClaimAmtReimbursed'].sum()\n",
    "outreimburse_temp1=pd.DataFrame([outreimburse_by_provider.index,outreimburse_by_provider])\n",
    "outreimburse_temp2=outreimburse_temp1.transpose()\n",
    "Out_Provider_Claim=outreimburse_temp2.rename({0:'Provider',1:'Outpatient_Claim_Amount'},axis=1)\n",
    "#Out_Provider_Claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the inpatient and outpatient claim amounts per provider dataframes\n",
    "provider_claimamount=pd.merge(In_Provider_Claim,Out_Provider_Claim,on='Provider',how='outer')\n",
    "#provider_claimamount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge provider fraud data wth claim number and claim amount datasets\n",
    "provider_list1=pd.merge(fraud_tr,provider_claimnumber,on='Provider',how='outer')\n",
    "#provider_list1\n",
    "provider_list2=pd.merge(provider_list1,provider_claimamount,on='Provider',how='outer')\n",
    "#provider_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create arrays for the features and the response variable\n",
    "provider_clean=provider_list2.fillna(0)\n",
    "y = provider_clean['PotentialFraud'].values\n",
    "X = provider_clean.drop(['PotentialFraud','Provider'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Use K nearest neighbors for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 8}"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GridSearchCV to choose hyperparameter for KNN, n_neighbors\n",
    "# Do hyperparameter tuning on training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)\n",
    "param_grid = {'n_neighbors': np.arange(1, 15)}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, param_grid, cv=5)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "knn_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=knn_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.98      0.95      0.96      1521\n",
      "         Yes       0.47      0.70      0.56       102\n",
      "\n",
      "    accuracy                           0.93      1623\n",
      "   macro avg       0.72      0.82      0.76      1623\n",
      "weighted avg       0.95      0.93      0.94      1623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1440   81]\n",
      " [  31   71]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: KNN is not a good method with <50% sensitivity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Use logistic regression for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings. filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 0.05179474679231213, 'penalty': 'l1'}\n",
      "Tuned Logistic Regression Accuracy: 0.9355690520200687\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "c_space = np.logspace(-5, 8, 15)\n",
    "param_grid = {'C': c_space, 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Instantiate the logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Create train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=21,stratify=y)\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg,param_grid,cv=5)\n",
    "\n",
    "# Fit it to the training data\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=logreg_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1449   82]\n",
      " [  22   70]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.99      0.95      0.97      1531\n",
      "         Yes       0.46      0.76      0.57        92\n",
      "\n",
      "    accuracy                           0.94      1623\n",
      "   macro avg       0.72      0.85      0.77      1623\n",
      "weighted avg       0.96      0.94      0.94      1623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: logistic regression is not a good method with <50% sensitivity, but oversampling the positive cases may help. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('No', 3433), ('Yes', 3433)]\n"
     ]
    }
   ],
   "source": [
    "# Use oversampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=21)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameter: {'C': 11787686.347935867, 'penalty': 'l1'}\n",
      "Tuned Logistic Regression Accuracy: 0.8598893096417128\n"
     ]
    }
   ],
   "source": [
    "# Fit logistic regression to the over-sampled data\n",
    "logreg_cv.fit(X_resampled,y_resampled)\n",
    "# Print the optimal parameters and best score\n",
    "print(\"Tuned Logistic Regression Parameter: {}\".format(logreg_cv.best_params_))\n",
    "print(\"Tuned Logistic Regression Accuracy: {}\".format(logreg_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=logreg_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1338   34]\n",
      " [ 133  118]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8429505527925865\n",
      "(array([0.90958532, 0.77631579]), array([0.77631579, 0.90958532]), array([1471,  152]))\n"
     ]
    }
   ],
   "source": [
    "print(balanced_accuracy_score(y_test, y_pred))\n",
    "print(sensitivity_specificity_support(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: logistic regression with oversampling the positive cases have dramatically improved the accuracy with sensitivity of 78% sensitivity and 91% specificity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Use Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 50}"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try Gridsearch on original imbalanced sampling\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)\n",
    "param_grid = {'n_estimators': np.arange(50, 100)}\n",
    "model=RandomForestClassifier(random_state=21)\n",
    "rf_cv = GridSearchCV(model, param_grid, cv=5)\n",
    "rf_cv.fit(X_train, y_train)\n",
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9229821318545902"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=rf_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1426   80]\n",
      " [  45   72]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.97      0.95      0.96      1506\n",
      "         Yes       0.47      0.62      0.54       117\n",
      "\n",
      "    accuracy                           0.92      1623\n",
      "   macro avg       0.72      0.78      0.75      1623\n",
      "weighted avg       0.93      0.92      0.93      1623\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: random forests is not working very well on the imbalanced data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda install -y -c conda-forge imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda update -y -n base -c defaults conda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try random forest with balanced sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 67}"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': np.arange(50, 100)}\n",
    "brf = BalancedRandomForestClassifier(random_state=21)\n",
    "brf_cv = GridSearchCV(brf, param_grid, cv=5)\n",
    "brf_cv.fit(X_train, y_train)\n",
    "brf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8602320297685069\n",
      "(array([0.83888511, 0.88157895]), array([0.88157895, 0.83888511]), array([1471,  152]))\n"
     ]
    }
   ],
   "source": [
    "y_pred = brf_cv.predict(X_test)\n",
    "print(balanced_accuracy_score(y_test, y_pred))\n",
    "print(sensitivity_specificity_support(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1234   18]\n",
      " [ 237  134]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest with balanced data improved the performance to 88% sensitivity and 84% specificity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_clean=provider_list2.fillna(0)\n",
    "y = provider_clean['PotentialFraud'].values\n",
    "X = provider_clean.drop(['PotentialFraud','Provider'], axis=1).values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try balanced bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8247052667358403"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bbc = BalancedBaggingClassifier(base_estimator=DecisionTreeClassifier(), sampling_strategy='auto', replacement=False,\n",
    "                               random_state=21)\n",
    "bbc.fit(X_train, y_train) \n",
    "y_pred = bbc.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.87967369, 0.76973684]), array([0.76973684, 0.87967369]), array([1471,  152]))\n"
     ]
    }
   ],
   "source": [
    "print(sensitivity_specificity_support(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1294   35]\n",
      " [ 177  117]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced bagging is not the best method with 77% sensitivity and 88% specificity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 73}"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "param_grid = {'n_estimators': np.arange(50, 100)}\n",
    "rusboost = RUSBoostClassifier(algorithm='SAMME.R',random_state=21)\n",
    "rusboost_cv = GridSearchCV(rusboost, param_grid, cv=5)\n",
    "rusboost_cv.fit(X_train, y_train)\n",
    "rusboost_cv.best_params_\n",
    "#rusboost = RUSBoostClassifier(n_estimators=50, algorithm='SAMME.R',random_state=0)\n",
    "#rusboost.fit(X_train, y_train)  \n",
    "#y_pred = rusboost.predict(X_test)\n",
    "#balanced_accuracy_score(y_test, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8423154674585853\n",
      "[[1220   22]\n",
      " [ 251  130]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = rusboost_cv.predict(X_test)\n",
    "print(balanced_accuracy_score(y_test, y_pred))  \n",
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.82936778, 0.85526316]), array([0.85526316, 0.82936778]), array([1471,  152]))\n"
     ]
    }
   ],
   "source": [
    "print(sensitivity_specificity_support(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting has 86% sensitivity and 83% specificity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try Adaboosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8561419907689005"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "eec = EasyEnsembleClassifier(random_state=21)\n",
    "eec.fit(X_train, y_train) \n",
    "y_pred = eec.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1251   21]\n",
      " [ 220  131]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.85044188, 0.86184211]), array([0.86184211, 0.85044188]), array([1471,  152]))\n"
     ]
    }
   ],
   "source": [
    "print(sensitivity_specificity_support(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaboosting has the 86% sensitivity and 85% specificity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Predicting the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the test datasets: there are four, one with provider information, one with beneficiary data, and two with claim data. \n",
    "fraud_tx = pd.read_csv('/Users/zhengzhang/Downloads/healthcare-provider-fraud-detection-analysis/Test-1542969243754.csv')\n",
    "bene_tx = pd.read_csv('/Users/zhengzhang/Downloads/healthcare-provider-fraud-detection-analysis/Test_Beneficiarydata-1542969243754.csv')\n",
    "inpatient_tx = pd.read_csv('/Users/zhengzhang/Downloads/healthcare-provider-fraud-detection-analysis/Test_Inpatientdata-1542969243754.csv')\n",
    "outpatient_tx = pd.read_csv('/Users/zhengzhang/Downloads/healthcare-provider-fraud-detection-analysis/Test_Outpatientdata-1542969243754.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the test dataset for prediction\n",
    "In_Provider=pd.DataFrame([inpatient_tx['Provider'].value_counts().index,inpatient_tx['Provider'].value_counts()]).transpose().rename({0:'Provider',1:'Inpatient_Claim_Number'},axis=1)\n",
    "Out_Provider=pd.DataFrame([outpatient_tx['Provider'].value_counts().index,outpatient_tx['Provider'].value_counts()]).transpose().rename({0:'Provider',1:'Outpatient_Claim_Number'},axis=1)\n",
    "provider_claimnumber=pd.merge(In_Provider,Out_Provider,on='Provider',how='outer')\n",
    "inreimburse_by_provider=inpatient_tx.groupby('Provider')['InscClaimAmtReimbursed'].sum()\n",
    "inreimburse_temp1=pd.DataFrame([inreimburse_by_provider.index,inreimburse_by_provider])\n",
    "inreimburse_temp2=inreimburse_temp1.transpose()\n",
    "In_Provider_Claim=inreimburse_temp2.rename({0:'Provider',1:'Inpatient_Claim_Amount'},axis=1)\n",
    "outreimburse_by_provider=outpatient_tx.groupby('Provider')['InscClaimAmtReimbursed'].sum()\n",
    "outreimburse_temp1=pd.DataFrame([outreimburse_by_provider.index,outreimburse_by_provider])\n",
    "outreimburse_temp2=outreimburse_temp1.transpose()\n",
    "Out_Provider_Claim=outreimburse_temp2.rename({0:'Provider',1:'Outpatient_Claim_Amount'},axis=1)\n",
    "provider_claimamount=pd.merge(In_Provider_Claim,Out_Provider_Claim,on='Provider',how='outer')\n",
    "provider_list1=pd.merge(fraud_tx,provider_claimnumber,on='Provider',how='outer')\n",
    "provider_list2=pd.merge(provider_list1,provider_claimamount,on='Provider',how='outer')\n",
    "provider_clean=provider_list2.fillna(0)\n",
    "provider_clean\n",
    "X = provider_clean.drop(['Provider'], axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     1070\n",
       "Yes     283\n",
       "dtype: int64"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoosting\n",
    "eec_pred = eec.predict(X)\n",
    "pd.value_counts(eec_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     1047\n",
       "Yes     306\n",
       "dtype: int64"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rusboosting\n",
    "rus_pred = rusboost_cv.predict(X)\n",
    "pd.value_counts(rus_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     1122\n",
       "Yes     231\n",
       "dtype: int64"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanced Bagging Classifier\n",
    "bbc_pred = bbc.predict(X)\n",
    "pd.value_counts(bbc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     1040\n",
       "Yes     313\n",
       "dtype: int64"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanced random forest\n",
    "brf_pred = brf_cv.predict(X)\n",
    "pd.value_counts(brf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     1137\n",
       "Yes     216\n",
       "dtype: int64"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression with oversampling\n",
    "logreg_pred = logreg_cv.predict(X)\n",
    "pd.value_counts(logreg_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>No</td>\n",
       "      <td>1039</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    No  Yes\n",
       "row_0           \n",
       "No     1039   98\n",
       "Yes       1  215"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest has a lot more positive cases than the logistic regression method. \n",
    "pd.crosstab(logreg_pred,brf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>No</td>\n",
       "      <td>1085</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Yes</td>\n",
       "      <td>37</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    No  Yes\n",
       "row_0           \n",
       "No     1085   52\n",
       "Yes      37  179"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanced bagging disagree with logistic regression a lot.\n",
    "pd.crosstab(logreg_pred,bbc_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>No</td>\n",
       "      <td>1067</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    No  Yes\n",
       "row_0           \n",
       "No     1067   70\n",
       "Yes       3  213"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adaboosting has a lot more positive cases than the logistic regression method. \n",
    "pd.crosstab(logreg_pred,eec_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>No</td>\n",
       "      <td>1024</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Yes</td>\n",
       "      <td>23</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    No  Yes\n",
       "row_0           \n",
       "No     1024  113\n",
       "Yes      23  193"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rusboosting disagree with logistic regression a lot.\n",
    "pd.crosstab(logreg_pred,rus_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
